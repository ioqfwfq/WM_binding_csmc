{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Memorability Analysis\n",
        "\n",
        "This notebook analyzes image memorability using two different pre-trained models:\n",
        "1. **ResMem**: A deep learning model specifically designed for memorability prediction\n",
        "2. **MemNet**: A Caffe-based model for image memorability analysis\n",
        "\n",
        "The analysis will provide memorability scores for each image, allowing for comparison between the two models and identification of highly memorable images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup and Dependencies\n",
        "\n",
        "First, let's install and import all necessary packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install resmem pandas pillow tqdm opencv-python numpy requests matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set up paths and parameters for the analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    # Image paths - Update this path to your image folder\n",
        "    IMAGE_FOLDER = r'.\\psychophysics\\stimuli2\\Animal'\n",
        "    \n",
        "    # MemNet model paths\n",
        "    MEMNET_PROTOTXT = 'memnet/deploy.prototxt'\n",
        "    MEMNET_MODEL = 'memnet/memnet.caffemodel'\n",
        "    \n",
        "    # Image processing settings\n",
        "    RESIZE_METHOD = 'stretch'  # Options: 'center_crop', 'resize_pad', 'stretch'\n",
        "    USE_CONSISTENT_PREPROCESSING = True  # Use same preprocessing for both models for fair comparison\n",
        "    \n",
        "    # Output paths\n",
        "    OUTPUT_DIR = 'results'\n",
        "    MEMORABILITY_SCORES_FILE = os.path.join(OUTPUT_DIR, 'memorability_scores.csv')\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "config = Config()\n",
        "print(f\"Image folder: {config.IMAGE_FOLDER}\")\n",
        "print(f\"Output directory: {config.OUTPUT_DIR}\")\n",
        "print(f\"Resize method: {config.RESIZE_METHOD}\")\n",
        "print(f\"Consistent preprocessing: {config.USE_CONSISTENT_PREPROCESSING}\")\n",
        "print()\n",
        "print(\"Resize method options:\")\n",
        "print(\"• 'center_crop': Scale and center crop (recommended, preserves aspect ratio)\")\n",
        "print(\"• 'resize_pad': Scale and pad with gray borders (preserves all content)\")\n",
        "print(\"• 'stretch': Simple stretch to 227x227 (may distort aspect ratio)\")\n",
        "print()\n",
        "print(\"Preprocessing consistency:\")\n",
        "print(f\"• True: Both models use same resizing method (fair comparison)\")\n",
        "print(f\"• False: Each model uses its own built-in preprocessing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. ResMem Implementation\n",
        "\n",
        "Load and set up the ResMem model for memorability prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from resmem import ResMem, transformer\n",
        "from torchvision import transforms\n",
        "\n",
        "# Load ResMem model\n",
        "resmem_model = ResMem(pretrained=True)\n",
        "resmem_model.eval()\n",
        "\n",
        "# ResMem preprocessing options\n",
        "print(\"=\" * 60)\n",
        "print(\"RESMEM PREPROCESSING OPTIONS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"ResMem typically uses its own preprocessing, but for fair comparison\")\n",
        "print(\"with MemNet, we can use consistent preprocessing for both models.\")\n",
        "print()\n",
        "print(\"Options:\")\n",
        "print(\"1. use_builtin=True: Use ResMem's built-in transformer (default)\")\n",
        "print(\"2. use_builtin=False: Use same preprocessing as MemNet for fair comparison\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def preprocess_image_resmem(image_path, resize_method='center_crop', use_builtin=True):\n",
        "    \"\"\"\n",
        "    Preprocess image for ResMem model.\n",
        "    \n",
        "    Args:\n",
        "        image_path (str): Path to input image\n",
        "        resize_method (str): Method for resizing ('center_crop', 'resize_pad', 'stretch')\n",
        "        use_builtin (bool): If True, use ResMem's built-in transformer; \n",
        "                           If False, use same preprocessing as MemNet\n",
        "        \n",
        "    Returns:\n",
        "        torch.Tensor: Preprocessed image tensor ready for ResMem\n",
        "    \"\"\"\n",
        "    if use_builtin:\n",
        "        # Use ResMem's built-in preprocessing\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        tensor = transformer(img).unsqueeze(0)\n",
        "        return tensor\n",
        "    else:\n",
        "        # Use consistent preprocessing (same as MemNet but for PyTorch)\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        # Use same smart resizing as MemNet - but need to check ResMem's expected size\n",
        "        # Let's use the same 227x227 as MemNet for true consistency\n",
        "        img = resize_image_smart(img, target_size=227, method=resize_method)\n",
        "        \n",
        "        # Convert to tensor and normalize (PyTorch format)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet RGB means\n",
        "                               std=[0.229, 0.224, 0.225])     # ImageNet RGB stds\n",
        "        ])\n",
        "        \n",
        "        tensor = transform(img).unsqueeze(0)\n",
        "        return tensor\n",
        "\n",
        "def predict_resmem(image_path, resize_method='center_crop', use_consistent_preprocessing=True):\n",
        "    \"\"\"\n",
        "    Predict memorability score using ResMem model.\n",
        "    \n",
        "    Args:\n",
        "        image_path (str): Path to input image\n",
        "        resize_method (str): Method for resizing ('center_crop', 'resize_pad', 'stretch')\n",
        "        use_consistent_preprocessing (bool): If True, use same preprocessing as MemNet;\n",
        "                                           If False, use ResMem's built-in preprocessing\n",
        "        \n",
        "    Returns:\n",
        "        float or None: Memorability score or None if error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        if use_consistent_preprocessing:\n",
        "            # Use same preprocessing as MemNet: intelligent resizing to 227x227\n",
        "            img_resized = resize_image_smart(img, target_size=227, method=resize_method)\n",
        "            \n",
        "            # Apply ResMem's transformer to the resized image\n",
        "            image_x = transformer(img_resized)\n",
        "            \n",
        "            # CRITICAL: Use the official ResMem reshape as shown in documentation\n",
        "            # prediction = model(image_x.view(-1, 3, 227, 227))\n",
        "            prediction = resmem_model(image_x.view(-1, 3, 227, 227))\n",
        "        else:\n",
        "            # Use ResMem's built-in preprocessing (original method)\n",
        "            image_x = transformer(img)\n",
        "            prediction = resmem_model(image_x.view(-1, 3, 227, 227))\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            score = prediction.item()\n",
        "        return score\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"ResMem model loaded successfully!\")\n",
        "print(\"Default: Using consistent preprocessing for fair comparison with MemNet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. MemNet Implementation\n",
        "\n",
        "Load and set up the MemNet model for memorability prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MemNet Preprocessing Requirements Documentation\n",
        "print(\"=\" * 60)\n",
        "print(\"MEMNET PREPROCESSING REQUIREMENTS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"MemNet is a Caffe-based model from MIT for image memorability prediction.\")\n",
        "print(\"Requirements for proper preprocessing:\")\n",
        "print()\n",
        "print(\"1. INPUT SIZE: 227x227 pixels (fixed size)\")\n",
        "print(\"2. COLOR FORMAT: RGB -> BGR conversion required\")\n",
        "print(\"3. NORMALIZATION: Mean subtraction with ImageNet means\")\n",
        "print(\"4. DATA TYPE: Float32\")\n",
        "print(\"5. FORMAT: NCHW (Batch, Channels, Height, Width)\")\n",
        "print()\n",
        "print(\"Preprocessing steps:\")\n",
        "print(\"- Load image as RGB\")\n",
        "print(\"- Resize to 227x227\")\n",
        "print(\"- Convert RGB to BGR (reverse channel order)\")\n",
        "print(\"- Subtract ImageNet BGR means: [104.0, 117.0, 123.0]\")\n",
        "print(\"- Convert to blob format for OpenCV DNN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load MemNet model (requires model files)\n",
        "try:\n",
        "    if not os.path.exists(config.MEMNET_PROTOTXT) or not os.path.exists(config.MEMNET_MODEL):\n",
        "        print(\"Warning: MemNet model files not found.\")\n",
        "        print(\"To download MemNet model files:\")\n",
        "        print(\"1. Visit: http://memorability.csail.mit.edu/\")\n",
        "        print(\"2. Download deploy.prototxt and memnet.caffemodel\")\n",
        "        print(\"3. Place them in the 'memnet/' directory\")\n",
        "        print(f\"Expected files: {config.MEMNET_PROTOTXT}, {config.MEMNET_MODEL}\")\n",
        "        memnet = None\n",
        "    else:\n",
        "        memnet = cv2.dnn.readNetFromCaffe(config.MEMNET_PROTOTXT, config.MEMNET_MODEL)\n",
        "        print(\"MemNet model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MemNet: {str(e)}\")\n",
        "    memnet = None\n",
        "\n",
        "def resize_image_smart(img, target_size=227, method='center_crop'):\n",
        "    \"\"\"\n",
        "    Resize image to target size using different methods to preserve quality.\n",
        "    \n",
        "    Args:\n",
        "        img (PIL.Image): Input image\n",
        "        target_size (int): Target size (227 for MemNet)\n",
        "        method (str): Resizing method - 'center_crop', 'resize_pad', or 'stretch'\n",
        "    \n",
        "    Returns:\n",
        "        PIL.Image: Resized image\n",
        "    \"\"\"\n",
        "    width, height = img.size\n",
        "    \n",
        "    if method == 'center_crop':\n",
        "        # Resize maintaining aspect ratio, then center crop\n",
        "        # This is the most common approach for computer vision models\n",
        "        \n",
        "        # Calculate the scale to make the smaller dimension equal to target_size\n",
        "        scale = max(target_size / width, target_size / height)\n",
        "        new_width = int(width * scale)\n",
        "        new_height = int(height * scale)\n",
        "        \n",
        "        # Resize maintaining aspect ratio\n",
        "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "        \n",
        "        # Center crop to target_size x target_size\n",
        "        left = (new_width - target_size) // 2\n",
        "        top = (new_height - target_size) // 2\n",
        "        right = left + target_size\n",
        "        bottom = top + target_size\n",
        "        \n",
        "        img = img.crop((left, top, right, bottom))\n",
        "        \n",
        "    elif method == 'resize_pad':\n",
        "        # Resize maintaining aspect ratio, then pad to square\n",
        "        # This preserves all content but may add borders\n",
        "        \n",
        "        # Calculate scale to fit within target_size x target_size\n",
        "        scale = min(target_size / width, target_size / height)\n",
        "        new_width = int(width * scale)\n",
        "        new_height = int(height * scale)\n",
        "        \n",
        "        # Resize maintaining aspect ratio\n",
        "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "        \n",
        "        # Create new image with target size and paste resized image in center\n",
        "        new_img = Image.new('RGB', (target_size, target_size), (128, 128, 128))  # Gray padding\n",
        "        paste_x = (target_size - new_width) // 2\n",
        "        paste_y = (target_size - new_height) // 2\n",
        "        new_img.paste(img, (paste_x, paste_y))\n",
        "        img = new_img\n",
        "        \n",
        "    elif method == 'stretch':\n",
        "        # Simple stretch to target size (can distort aspect ratio)\n",
        "        img = img.resize((target_size, target_size), Image.LANCZOS)\n",
        "        \n",
        "    else:\n",
        "        raise ValueError(f\"Unknown resize method: {method}\")\n",
        "    \n",
        "    return img\n",
        "\n",
        "def preprocess_image_memnet(image_path, resize_method='center_crop'):\n",
        "    \"\"\"\n",
        "    Preprocess image for MemNet model according to official requirements.\n",
        "    \n",
        "    MemNet preprocessing steps:\n",
        "    1. Load and convert to RGB\n",
        "    2. Resize to 227x227 pixels (using smart resizing)\n",
        "    3. Convert to float32\n",
        "    4. Convert RGB to BGR (OpenCV/Caffe format)\n",
        "    5. Subtract ImageNet BGR means: [104.0, 117.0, 123.0]\n",
        "    6. Convert to blob format (NCHW)\n",
        "    \n",
        "    Args:\n",
        "        image_path (str): Path to input image\n",
        "        resize_method (str): Method for resizing ('center_crop', 'resize_pad', 'stretch')\n",
        "        \n",
        "    Returns:\n",
        "        np.ndarray: Preprocessed image blob ready for MemNet\n",
        "    \"\"\"\n",
        "    # Load image as RGB\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    \n",
        "    # Smart resize to required input size\n",
        "    img = resize_image_smart(img, target_size=227, method=resize_method)\n",
        "    \n",
        "    # Convert to numpy array and float32\n",
        "    img = np.array(img).astype(np.float32)\n",
        "    \n",
        "    # Convert RGB to BGR (Caffe/OpenCV convention)\n",
        "    img = img[:, :, ::-1]\n",
        "    \n",
        "    # Subtract ImageNet BGR means\n",
        "    # These are the standard ImageNet means in BGR order\n",
        "    mean = np.array([104.0, 117.0, 123.0])\n",
        "    img -= mean\n",
        "    \n",
        "    # Convert to blob format (adds batch dimension and reorders to NCHW)\n",
        "    blob = cv2.dnn.blobFromImage(img)\n",
        "    \n",
        "    return blob\n",
        "\n",
        "def predict_memnet(image_path, resize_method='center_crop'):\n",
        "    \"\"\"\n",
        "    Predict memorability score using MemNet model.\n",
        "    \n",
        "    Args:\n",
        "        image_path (str): Path to input image\n",
        "        resize_method (str): Method for resizing ('center_crop', 'resize_pad', 'stretch')\n",
        "        \n",
        "    Returns:\n",
        "        float or None: Memorability score (0-1) or None if error\n",
        "    \"\"\"\n",
        "    if memnet is None:\n",
        "        return None\n",
        "    try:\n",
        "        # Preprocess image with specified resize method\n",
        "        blob = preprocess_image_memnet(image_path, resize_method=resize_method)\n",
        "        \n",
        "        # Set input and run forward pass\n",
        "        memnet.setInput(blob)\n",
        "        pred = memnet.forward()\n",
        "        \n",
        "        # Extract memorability score\n",
        "        score = float(pred[0][0])\n",
        "        \n",
        "        return score\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Image Processing and Analysis\n",
        "\n",
        "Process images and calculate memorability scores using both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_images(image_folder):\n",
        "    \"\"\"Process all images in the folder using both models.\"\"\"\n",
        "    if not os.path.exists(image_folder):\n",
        "        print(f\"Warning: Image folder '{image_folder}' not found.\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {image_folder}\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    print(f\"Found {len(image_files)} images to process\")\n",
        "    \n",
        "    results = []\n",
        "    for fname in tqdm(image_files, desc=\"Processing images\"):\n",
        "        image_path = os.path.join(image_folder, fname)\n",
        "        \n",
        "        # Get predictions from both models using consistent preprocessing\n",
        "        resmem_score = predict_resmem(\n",
        "            image_path, \n",
        "            resize_method=config.RESIZE_METHOD,\n",
        "            use_consistent_preprocessing=config.USE_CONSISTENT_PREPROCESSING\n",
        "        )\n",
        "        memnet_score = predict_memnet(image_path, resize_method=config.RESIZE_METHOD)\n",
        "        \n",
        "        results.append({\n",
        "            'filename': fname,\n",
        "            'resmem_score': resmem_score,\n",
        "            'memnet_score': memnet_score\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Check if image folder exists before processing\n",
        "if os.path.exists(config.IMAGE_FOLDER):\n",
        "    print(f\"Processing images from: {config.IMAGE_FOLDER}\")\n",
        "    df = process_images(config.IMAGE_FOLDER)\n",
        "    \n",
        "    # Save results\n",
        "    if not df.empty:\n",
        "        df.to_csv(config.MEMORABILITY_SCORES_FILE, index=False)\n",
        "        print(f\"Results saved to: {config.MEMORABILITY_SCORES_FILE}\")\n",
        "        print(f\"Processed {len(df)} images\")\n",
        "        df.head()\n",
        "    else:\n",
        "        print(\"No results to display\")\n",
        "else:\n",
        "    print(f\"Image folder not found: {config.IMAGE_FOLDER}\")\n",
        "    print(\"Please update the IMAGE_FOLDER path in the Configuration section\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Results Analysis and Visualization\n",
        "\n",
        "Analyze and visualize the memorability scores from both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_results(df):\n",
        "    \"\"\"Analyze and visualize memorability scores.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data to analyze\")\n",
        "        return df\n",
        "    \n",
        "    # Remove rows with missing scores\n",
        "    df_clean = df.dropna()\n",
        "    \n",
        "    if df_clean.empty:\n",
        "        print(\"No valid data to analyze\")\n",
        "        return df\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(\"Basic Statistics:\")\n",
        "    print(df_clean[['resmem_score', 'memnet_score']].describe())\n",
        "    \n",
        "    # Check if both models have valid scores\n",
        "    resmem_valid = df_clean['resmem_score'].notna().sum()\n",
        "    memnet_valid = df_clean['memnet_score'].notna().sum()\n",
        "    \n",
        "    print(f\"\\nValid scores - ResMem: {resmem_valid}, MemNet: {memnet_valid}\")\n",
        "    \n",
        "    # Spearman rank correlation between models (if both have valid scores)\n",
        "    if resmem_valid > 0 and memnet_valid > 0:\n",
        "        df_both = df_clean.dropna(subset=['resmem_score', 'memnet_score'])\n",
        "        if len(df_both) > 1:\n",
        "            # Calculate both Pearson and Spearman correlations for comparison\n",
        "            pearson_corr = df_both['resmem_score'].corr(df_both['memnet_score'], method='pearson')\n",
        "            spearman_corr = df_both['resmem_score'].corr(df_both['memnet_score'], method='spearman')\n",
        "            \n",
        "            print(f\"Pearson correlation (linear): {pearson_corr:.3f}\")\n",
        "            print(f\"Spearman rank correlation: {spearman_corr:.3f}\")\n",
        "            print()\n",
        "            \n",
        "            # Interpret the Spearman correlation\n",
        "            if spearman_corr >= 0.7:\n",
        "                rank_strength = \"Strong\"\n",
        "            elif spearman_corr >= 0.4:\n",
        "                rank_strength = \"Moderate\"\n",
        "            elif spearman_corr >= 0.2:\n",
        "                rank_strength = \"Weak\"\n",
        "            else:\n",
        "                rank_strength = \"Very weak\"\n",
        "            \n",
        "            print(f\"Rank correlation interpretation: {rank_strength}\")\n",
        "            print(\"→ This measures how well the models agree on relative ordering of images\")\n",
        "            \n",
        "            # Add ranking analysis\n",
        "            print(f\"\\nRanking Analysis:\")\n",
        "            df_both['resmem_rank'] = df_both['resmem_score'].rank(ascending=False)\n",
        "            df_both['memnet_rank'] = df_both['memnet_score'].rank(ascending=False)\n",
        "            df_both['rank_diff'] = abs(df_both['resmem_rank'] - df_both['memnet_rank'])\n",
        "            \n",
        "            # Show images with highest agreement (small rank differences)\n",
        "            high_agreement = df_both.nsmallest(3, 'rank_diff')\n",
        "            print(\"Top 3 images with highest ranking agreement:\")\n",
        "            for _, row in high_agreement.iterrows():\n",
        "                print(f\"  {row['filename']}: ResMem rank {row['resmem_rank']:.0f}, MemNet rank {row['memnet_rank']:.0f} (diff: {row['rank_diff']:.0f})\")\n",
        "            \n",
        "            # Show images with highest disagreement (large rank differences)\n",
        "            high_disagreement = df_both.nlargest(3, 'rank_diff')\n",
        "            print(\"Top 3 images with highest ranking disagreement:\")\n",
        "            for _, row in high_disagreement.iterrows():\n",
        "                print(f\"  {row['filename']}: ResMem rank {row['resmem_rank']:.0f}, MemNet rank {row['memnet_rank']:.0f} (diff: {row['rank_diff']:.0f})\")\n",
        "    \n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    \n",
        "    # Distribution of scores\n",
        "    plt.subplot(1, 3, 1)\n",
        "    if resmem_valid > 0:\n",
        "        plt.hist(df_clean['resmem_score'].dropna(), alpha=0.7, label='ResMem', bins=20)\n",
        "    if memnet_valid > 0:\n",
        "        plt.hist(df_clean['memnet_score'].dropna(), alpha=0.7, label='MemNet', bins=20)\n",
        "    plt.title('Distribution of Memorability Scores')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    \n",
        "    # Box plot\n",
        "    plt.subplot(1, 3, 2)\n",
        "    data_to_plot = []\n",
        "    labels = []\n",
        "    if resmem_valid > 0:\n",
        "        data_to_plot.append(df_clean['resmem_score'].dropna())\n",
        "        labels.append('ResMem')\n",
        "    if memnet_valid > 0:\n",
        "        data_to_plot.append(df_clean['memnet_score'].dropna())\n",
        "        labels.append('MemNet')\n",
        "    \n",
        "    if data_to_plot:\n",
        "        plt.boxplot(data_to_plot, labels=labels)\n",
        "        plt.title('Score Distribution Comparison')\n",
        "        plt.ylabel('Score')\n",
        "    \n",
        "    # Scatter plot (if both models have data)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    if resmem_valid > 0 and memnet_valid > 0:\n",
        "        df_both = df_clean.dropna(subset=['resmem_score', 'memnet_score'])\n",
        "        if len(df_both) > 0:\n",
        "            plt.scatter(df_both['resmem_score'], df_both['memnet_score'], alpha=0.6)\n",
        "            plt.xlabel('ResMem Score')\n",
        "            plt.ylabel('MemNet Score')\n",
        "            plt.title('ResMem vs MemNet Scores')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'Need both models\\nfor comparison', \n",
        "                ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Model Comparison')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Analyze results if data exists\n",
        "if 'df' in globals() and not df.empty:\n",
        "    analyzed_df = analyze_results(df)\n",
        "else:\n",
        "    print(\"No data to analyze. Please run the image processing cell first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
